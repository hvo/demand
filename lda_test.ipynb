{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import pickle\n",
    "from datetime import datetime, date, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook is for testing PySpark algorithms/strategy. A non-notebook python script will be generated separately for use on NYU's Dumbo cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.0\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Jul  2 2016 17:43:17)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "# get a sparkContext as sc\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x111b1bcd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/region_shapes.pickle', 'rb') as handle:\n",
    "    region_shapes = pickle.load(handle)\n",
    "\n",
    "with open('./data/anoms.pickle', 'rb') as handle:\n",
    "    anoms_key = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EIA_Region</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>California</th>\n",
       "      <td>(POLYGON ((-114.2997240000745 34.1588979998338...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Carolinas</th>\n",
       "      <td>(POLYGON ((-77.94237900003289 36.5445129996888...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Central</th>\n",
       "      <td>(POLYGON ((-102.5477049998308 46.2827879998399...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <td>(POLYGON ((-82.11678699982296 24.5491439996071...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mid Atlantic</th>\n",
       "      <td>(POLYGON ((-84.82944799969027 38.8971309999546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Midwest</th>\n",
       "      <td>(POLYGON ((-89.87456199992369 34.3342880000746...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New England</th>\n",
       "      <td>(POLYGON ((-68.36510700029049 44.1014639998632...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <td>(POLYGON ((-72.16159800009964 41.1895390001785...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Northwest</th>\n",
       "      <td>(POLYGON ((-122.5850379996938 48.3951660000205...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southern</th>\n",
       "      <td>(POLYGON ((-88.08681199961534 30.2598640003873...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Southwest</th>\n",
       "      <td>(POLYGON ((-109.0458339999296 37.3616780000081...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texas</th>\n",
       "      <td>(POLYGON ((-96.39784600010417 28.3435129998347...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TVA</th>\n",
       "      <td>POLYGON ((-81.52127999985737 35.88586000013065...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       geometry\n",
       "EIA_Region                                                     \n",
       "California    (POLYGON ((-114.2997240000745 34.1588979998338...\n",
       "Carolinas     (POLYGON ((-77.94237900003289 36.5445129996888...\n",
       "Central       (POLYGON ((-102.5477049998308 46.2827879998399...\n",
       "Florida       (POLYGON ((-82.11678699982296 24.5491439996071...\n",
       "Mid Atlantic  (POLYGON ((-84.82944799969027 38.8971309999546...\n",
       "Midwest       (POLYGON ((-89.87456199992369 34.3342880000746...\n",
       "New England   (POLYGON ((-68.36510700029049 44.1014639998632...\n",
       "New York      (POLYGON ((-72.16159800009964 41.1895390001785...\n",
       "Northwest     (POLYGON ((-122.5850379996938 48.3951660000205...\n",
       "Southern      (POLYGON ((-88.08681199961534 30.2598640003873...\n",
       "Southwest     (POLYGON ((-109.0458339999296 37.3616780000081...\n",
       "Texas         (POLYGON ((-96.39784600010417 28.3435129998347...\n",
       "TVA           POLYGON ((-81.52127999985737 35.88586000013065..."
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_shapes.set_index('EIA_Region', drop=True, inplace=True)\n",
    "region_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central</td>\n",
       "      <td>2015-12-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central</td>\n",
       "      <td>2016-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Central</td>\n",
       "      <td>2016-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Central</td>\n",
       "      <td>2016-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Central</td>\n",
       "      <td>2016-01-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    region   datetime\n",
       "0  Central 2015-12-03\n",
       "1  Central 2016-01-06\n",
       "2  Central 2016-01-11\n",
       "3  Central 2016-01-12\n",
       "4  Central 2016-01-13"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anoms_df = pd.DataFrame(anoms_key, columns=['region', 'datetime'])\n",
    "anoms_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_bq_date(stamp):\n",
    "    \"\"\"\n",
    "    converts datetime objects into date strings suitable for google BigQuery SQL syntax\n",
    "    \"\"\"\n",
    "    y = str(stamp.year)\n",
    "    m = str(stamp.month)\n",
    "    d = str(stamp.day)\n",
    "    if len (m)==1:\n",
    "        m = '0' + m\n",
    "    if len (d)==1:\n",
    "        d = '0' + d\n",
    "    return int(y + m + d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get unique YYYYMMDD dates for BigQuery\n",
    "sql_dates = list(set(map(lambda anom: parse_bq_date(anom[1]), anoms_key)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "anoms_dict = {}\n",
    "for region, days in anoms_df.groupby('region'):\n",
    "    anoms_dict[region] = (list(set(map(parse_bq_date, days.datetime))),\n",
    "                         region_shapes.get_value(region, 'geometry'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write the anoms_dict to file, so we can use on compute cluster later\n",
    "with open('./data/anoms_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(anoms_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "LOCAL_PATH = './data/anoms*.gz'\n",
    "TEST_PATH = './data/anomstest.csv'\n",
    "#HDFS_PATH = ''\n",
    "\n",
    "anoms = sc.textFile(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert all lines to UTF-8 encoding\n",
    "anoms = anoms.map(lambda line: line.encode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'SQLDATE'),\n",
       " (1, 'Actor1Name'),\n",
       " (2, 'Actor1Type1Code'),\n",
       " (3, 'EventCode'),\n",
       " (4, 'QuadClass'),\n",
       " (5, 'AvgTone'),\n",
       " (6, 'ActionGeo_Fullname'),\n",
       " (7, 'ActionGeo_Lat'),\n",
       " (8, 'ActionGeo_Long'),\n",
       " (9, 'Actor1Geo_Fullname'),\n",
       " (10, 'Actor1Geo_Lat'),\n",
       " (11, 'Actor1Geo_Long')]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get field indexes for RDD\n",
    "list(enumerate(anoms.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove header row\n",
    "anoms = anoms.filter(lambda line: not line.startswith('SQL'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20151218,,,043,1,0,\"Akron, Ohio, United States\",41.0814,-81.519,,,',\n",
       " '20150816,,,112,3,-12.3076923076923,\"Akron, Ohio, United States\",41.0814,-81.519,,,',\n",
       " '20160124,,,046,1,-0.89285714285715,\"Akron, Ohio, United States\",41.0814,-81.519,,,',\n",
       " '20160104,,,040,1,0.98792535675083,\"Dover, Ohio, United States\",40.5206,-81.474,,,',\n",
       " '20151001,,,050,1,-2.13333333333333,\"Utica, Ohio, United States\",39.4976,-84.1602,,,']"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anoms.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_point(lng, lat):\n",
    "    return Point(float(lng), float(lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_events(events):\n",
    "    reader = csv.reader(events)\n",
    "    # for each event record\n",
    "    for event in reader:\n",
    "        # continue to look for regional matches until one is found and yielded\n",
    "        for region in anoms_dict.keys():\n",
    "            # check if datestamp within the regional set of interesting dates\n",
    "            try:\n",
    "                if int(event[0]) in anoms_dict[region][0]:\n",
    "                    # check if event location took place within region\n",
    "                    point = get_point(event[8], event[7])\n",
    "                    if point.within(anoms_dict[region][1]):\n",
    "                        yield (region,          # region\n",
    "                               (int(event[0]),   # date\n",
    "                               str(event[1]),   # actorname\n",
    "                               str(event[2]),   # actortype\n",
    "                               str(event[3]),   # eventcode\n",
    "                               int(event[4]),   # quadclass\n",
    "                               float(event[5]))) #tone  \n",
    "            except ValueError:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# map by partition for the initial reduction (heaviest lifting is here)\n",
    "reduced_anoms = anoms.mapPartitions(parse_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Texas', (20161220, '', '', '112', 3, -7.02875399361022)),\n",
       " ('Texas', (20170429, '', '', '112', 3, -11.6022099447514)),\n",
       " ('Northwest', (20161215, '', '', '130', 3, -4.31654676258993)),\n",
       " ('Texas', (20170109, '', '', '0874', 2, 0.0)),\n",
       " ('Texas', (20160811, '', '', '042', 1, -1.34408602150538)),\n",
       " ('Texas', (20170109, '', '', '060', 2, -5.34883720930232)),\n",
       " ('Texas', (20160811, '', '', '052', 1, 0.73529411764706)),\n",
       " ('Texas', (20151012, '', '', '036', 1, 4.29553264604811)),\n",
       " ('Texas', (20170108, '', '', '036', 1, 0.95969289827255)),\n",
       " ('Texas', (20161017, '', '', '042', 1, 1.47639739285009))]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_anoms.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def skip_missing(line, col_index):\n",
    "    return line[1][col_index] != ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def concat_for_count(line, col_index):\n",
    "    return (line[0] + '_' + str(line[1][col_index]), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resplit_regions(line):\n",
    "    return (line[0].split('_')[0], (line[0].split('_')[1], line[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_n(v, n):\n",
    "    return sorted(list(v), key=lambda x: x[1], reverse=True)[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_top_values(col_index, n):\n",
    "    \"\"\"\n",
    "    ARGS\n",
    "    - col_index:\n",
    "        1=actorname\n",
    "        2=actortype\n",
    "        3=eventcode\n",
    "        4=quadclass\n",
    "    - top n values\n",
    "    \"\"\"\n",
    "    return reduced_anoms.filter(lambda event: skip_missing(event, col_index)) \\\n",
    "        .map(lambda event: concat_for_count(event, col_index)) \\\n",
    "        .reduceByKey(lambda x, y: x + y) \\\n",
    "        .map(resplit_regions) \\\n",
    "        .groupByKey() \\\n",
    "        .mapValues(lambda counts: get_top_n(counts, n)) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Central', -2.5778306850976005),\n",
       " ('Southern', -2.329364268487252),\n",
       " ('New England', -1.5525235745149324),\n",
       " ('Florida', -2.388332896634119),\n",
       " ('California', -1.0773653697289698),\n",
       " ('TVA', -1.1582477193554037),\n",
       " ('Texas', -1.9694371392691459),\n",
       " ('Southwest', -1.6412355170788393),\n",
       " ('Northwest', -1.5152019623052377),\n",
       " ('Carolinas', -1.1544674277886582)]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get average TONE, by region\n",
    "reduced_anoms.filter(lambda event: skip_missing(event, 5)) \\\n",
    "        .map(lambda event: (event[0], event[1][5])) \\\n",
    "        .mapValues(lambda v: (v, 1)) \\\n",
    "        .reduceByKey(lambda a, b: (a[0]+b[0], a[1]+b[1])) \\\n",
    "        .mapValues(lambda v:v[0] / v[1]) \\\n",
    "        .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Central', [('UNITED STATES', 2), ('OKLAHOMA', 1), ('POLICE', 1)]),\n",
       " ('Southern', [('UNITED STATES', 3), ('SRI LANKA', 1), ('SWEDEN', 1)]),\n",
       " ('New England', [('INDUSTRY', 1), ('COLLEGE', 1), ('OBAMA', 1)]),\n",
       " ('Florida', [('UNITED STATES', 6), ('CHINA', 2), ('CUBAN', 2)]),\n",
       " ('California', [('UNITED STATES', 8), ('CHINA', 2), ('COMPANIES', 1)]),\n",
       " ('TVA', [('NASHVILLE', 6), ('UNITED STATES', 3), ('COMPANY', 1)]),\n",
       " ('Texas', [('UNITED STATES', 2), ('CHINESE', 1), ('PROFESSOR', 1)]),\n",
       " ('Southwest', [('MEXICO', 5), ('UNITED STATES', 4), ('NEW YORK', 1)]),\n",
       " ('Northwest', [('UNITED STATES', 12), ('DENVER', 4), ('POLICE', 4)]),\n",
       " ('Carolinas', [('UNITED STATES', 4), ('FIRE MARSHAL', 2), ('ARMY', 1)])]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_values(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Central', [('LEG', 1), ('ELI', 1), ('GOV', 1)]),\n",
       " ('Southern', [('COP', 1), ('GOV', 1), ('EDU', 1)]),\n",
       " ('New England', [('GOV', 2), ('EDU', 1), ('BUS', 1)]),\n",
       " ('Florida', [('GOV', 5), ('LEG', 2), ('JUD', 1)]),\n",
       " ('California', [('JUD', 2), ('CVL', 2), ('GOV', 2)]),\n",
       " ('TVA', [('ELI', 1), ('LEG', 1), ('BUS', 1)]),\n",
       " ('Texas', [('EDU', 2), ('REF', 1)]),\n",
       " ('Carolinas', [('GOV', 2), ('COP', 1), ('MIL', 1)]),\n",
       " ('Northwest', [('COP', 5), ('BUS', 4), ('MED', 3)]),\n",
       " ('Southwest', [('COP', 2), ('BUS', 1), ('GOV', 1)])]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_values(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Central', [('1', 15), ('3', 4), ('4', 1)]),\n",
       " ('Southern', [('1', 34), ('4', 8), ('3', 2), ('2', 1)]),\n",
       " ('New England', [('1', 3), ('4', 3), ('3', 1), ('2', 1)]),\n",
       " ('Florida', [('1', 56), ('4', 14), ('3', 7), ('2', 7)]),\n",
       " ('California', [('1', 156), ('4', 38), ('2', 20), ('3', 17)]),\n",
       " ('TVA', [('1', 20), ('4', 5), ('2', 3), ('3', 2)]),\n",
       " ('Texas', [('1', 52), ('4', 7), ('2', 7), ('3', 5)]),\n",
       " ('Southwest', [('1', 37), ('3', 10), ('4', 7), ('2', 4)]),\n",
       " ('Northwest', [('1', 69), ('4', 19), ('3', 10), ('2', 5)]),\n",
       " ('Carolinas', [('1', 27), ('4', 6), ('3', 3), ('2', 1)])]"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_values(4, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Central', [('042', 4), ('040', 3), ('036', 2), ('043', 2), ('112', 2)]),\n",
       " ('Southern', [('042', 13), ('040', 6), ('043', 4), ('173', 3), ('051', 3)]),\n",
       " ('New England', [('061', 1), ('186', 1), ('160', 1), ('010', 1), ('046', 1)]),\n",
       " ('Florida', [('020', 11), ('043', 10), ('042', 8), ('040', 7), ('173', 5)]),\n",
       " ('California',\n",
       "  [('042', 38), ('043', 27), ('040', 22), ('051', 17), ('036', 16)]),\n",
       " ('TVA', [('043', 5), ('042', 4), ('040', 3), ('190', 3), ('020', 3)]),\n",
       " ('Texas', [('042', 12), ('043', 11), ('036', 10), ('040', 7), ('190', 5)]),\n",
       " ('Carolinas', [('043', 6), ('042', 4), ('036', 4), ('051', 3), ('040', 3)]),\n",
       " ('Northwest',\n",
       "  [('042', 16), ('043', 11), ('040', 10), ('173', 8), ('020', 6)]),\n",
       " ('Southwest', [('042', 11), ('040', 9), ('190', 6), ('051', 4), ('010', 4)])]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_top_values(3, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "desired output\n",
    "\n",
    "regionally\n",
    "- most common actors, actor type, and event codes\n",
    "- counts of quad classes\n",
    "- average tone value"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
